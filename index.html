<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IllumiNeRF - 3D Relighting without Inverse Rendering</title>

  <link href="https://fonts.googleapis.com/css?family=Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title"><b>IllumiNeRF</b><br>3D Relighting without Inverse Rendering</h1>
            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://xiaoming-zhao.com/" target="_blank">Xiaoming Zhao</a><sup>1,3</sup>,</span>
              <span class="author-block">
                <a href="https://pratulsrinivasan.github.io/" target="_blank">Pratul P. Srinivasan</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://dorverbin.github.io/" target="_blank">Dor Verbin</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://keunhong.com/" target="_blank">Keunhong Park</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://ricardomartinbrualla.com/" target="_blank">Ricardo Martin-Brualla</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://henzler.github.io/" target="_blank">Philipp Henzler</a><sup>1</sup>
              </span>
            </div>
  
            <div class="is-size-4 publication-authors">
              <span class="author-block"><sup>1</sup>Google Research,</span>
              <span class="author-block"><sup>2</sup>Google DeepMind,</span>
              <span class="author-block"><sup>3</sup>University of Illinois Urbana-Champaign</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.06527" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
              <div class="publication-links">
                <span class="link-block">
                  <a href="./index.html" id="active-button" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fas fa-home"></i>
                    </span>
                    <span>Main Page</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="./stanford_orb.html" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fas fa-flask"></i>
                    </span>
                    <span>Stanford-ORB Results</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="./tensoir.html" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fas fa-flask"></i>
                    </span>
                    <span>TensoIR Results</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="./cat3d.html" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fas fa-flask"></i>
                    </span>
                    <span>CAT3D Results</span>
                  </a>
                </span>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="teaser">
    <div class="container is-max-desktop">
      <div class="columns is-mobile has-text-centered is-vcentered ">
        <div class="column is-full is-vcentered">
          <video class="video" loop playsinline muted autoplay controls src="./static/teaser.mp4"></video>
        </div>
      </div>
    </div>
  </section>

  <hr />

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified">
        <p>
          Existing methods for relightable view synthesis --- using a set of images of an object under unknown lighting to recover a 3D representation that can be rendered from novel viewpoints under a target illumination --- are based on inverse rendering,
          and attempt to disentangle the object geometry, materials, and lighting that explain the input images.
          Furthermore, this typically involves optimization through differentiable Monte Carlo rendering, which is brittle and computationally-expensive.
          In this work, we propose a simpler approach: we first relight each input image using an image diffusion model conditioned on lighting and then reconstruct a Neural Radiance Field (NeRF) with these relit images,
          from which we render novel views under the target lighting. We demonstrate that this strategy is surprisingly competitive and achieves state-of-the-art results on multiple relighting benchmarks.
        </p>
      </div>
    </div>
  </section>

  <hr />

  <section class="section">
    <div class="container is-max-desktop">
      <!-- method. -->
      <h2 class="title is-3">How It Works</h2>
      <!-- <div class="columns is-mobile has-text-centered is-size-7-mobile is-vcentered "> -->
      <div class="column is-full">
        <img src="./static/overview.png" />
        <br/>
        <div class="content has-text-left">
          <ol>
            <li>Given a set of images and camera poses in (a), we run NeRF to extract the 3D geometry as in (b);</li>
            <li>Based on this geometry and a target light shown in (c), we create radiance cues for each given input view as in (d);</li>
            <li>Next, we independently relight each input image using a Relighting Diffusion Model illustrated in (e) and sample S possible solutions for each given image displayed in (f);</li>
            <li>Finally, we distill the relit set of images into a 3D representation through a Latent NeRF optimization as in (g) and (h).</li>
          </ol>
        </div>
        <br/>
      </div>
      <!-- </div> -->

      <h3 class="title is-4">3D Consistent Relighting</h3>
      <div class="column is-full">
        <div class="content has-text-left">
          <ul style="margin-top: -20px;">
            <li><b>On the top</b>: we show renderings from our final latent NeRF;</li>
            <li><b>On the bottom</b>: we show a diffusion sample from the nearest training view corresponding to each rendered frame on the top.</li>
          </ul>
        </div>
      </div>

      <div class="columns is-mobile has-text-centered is-size-7-mobile is-vcentered ">
        <div class="column is-one-third">
          <video class="video" loop playsinline muted autoplay controls src="./static/diffusion_samples/vertical-stanford_orb-grogu_scene001-grogu_scene002.mp4"></video>
        </div>
        <div class="column is-one-third">
          <video class="video" loop playsinline muted autoplay controls src="./static/diffusion_samples/vertical-tensoir-hotdog-bridge.mp4"></video>
        </div>
        <div class="column is-one-third">
          <video class="video" loop playsinline muted autoplay controls src="./static/diffusion_samples/vertical-cat3d-unicorn-blinds.mp4"></video>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- method. -->
      <h2 class="title is-3">Related Works</h2>
      <div class="column is-full">
        <div class="content has-text-left">
          Check out the following concurrent works which also introduce a (single-image) relighting diffusion model.
          <!-- <a href="https://neural-gaffer.github.io/" target="_blank">Neural Gaffer</a> is also capable of 3D relighting. -->
          <ul>
            <li><a href="https://dilightnet.github.io/" target="_blank">DiLightNet: Fine-grained Lighting Control for Diffusion-based Image Generation</a></li>
            <li><a href="https://neural-gaffer.github.io/" target="_blank">Neural Gaffer: Relighting Any Object via Diffusion</a> (also capable of 3D relighting)</li>
            <li><a href="https://repo-sam.inria.fr/fungraph/generative-radiance-field-relighting/" target="_blank">A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis</a> (also capable of 3D relighting)</li>
          </ul>
        </div>
      </div>
  </section>

  <hr />

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhao2024illuminerf,
    author    = {Xiaoming Zhao and Pratul P. Srinivasan and Dor Verbin and Keunhong Park and Ricardo Martin Brualla and Philipp Henzler},
    title     = {{IllumiNeRF: 3D Relighting without Inverse Rendering}},
    journal   = {ArXiv},
    year      = {2024},
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
